[{"image_id": 84124, "prompt": "\nYou are an AI visual assistant that can generate certain type of high-quality Q&A about the images. You will always perform as if you are directly seeing an image. \n\nGoals: \nI will give you some information about this image, along with a question type. Your task is to generate a high-quality Q&A of this question type based on the image information provided. The question should be followed by four answer choices, with only one correct answer, along with an explanation. \n\nThe image information includes 5 descriptions and the locations of specific objects within the image given in the form of bounding boxes. The bounding boxes coordinates are represented as (x1, y1, x2, y2) with floating numbers ranging from 0 to 1. These values correspond to the top left x, top left y, bottom right x, and bottom right y. \n\nRules (If not specified, the following rules apply to all texts you generate): \n(1) Summarize the information provided by image descriptions and objects locations of this image to generate the high-quality Q&A, which should reflect the content of the image. \n(2) Don't generate imaginative or irrelevant content. Ensure all questions, answers, and explanations are strictly based on the information available in the image descriptions and object locations. Do not invent or speculate on details that are not contained in the provided image descriptions and object locations. Bounding boxes or objects not mentioned in the image information should not be generated. \n(3) You must always generate your responses as if you are directly viewing the image, not reading the image descriptions or object locations. Do not mention or refer to the image descriptions in your responses. Avoid phrases such as \"based on the description\" or \"according to the image information\" in your explanations. Instead, use phrases like \"upon observing the image\" or \"by looking at the image\".  \n(4) Do not ask questions that you cannot answer accurately with the given information. \n(5) In the choices, there should be only one correct answer to the question. At the same time, other choices should also be relevant to the question. \n(6) The question you ask should be also answerable without choices. \n(7) Be sure to structure your questions and answers according to the question type. If you find the requested type of question can't be accurately produced from the image information, please state 'Skip' and provide an explanation. \n(8) Don't give any clues or given conditions in question. Invoke visual information as much as possible. When asking questions about a certain object, if necessary, don't mention the name of it directly, but refer to it using its location described in natural language and characterization in the image, followed by its bounding box. When referring to a type of object that occur multiple times in the image (like 'person'), use specific characteristics given in the image descriptions to identify them properly. \n(9) The bounding boxes should not be used as the main identifying feature of the objects in the scene, but rather as a supplement to descriptive identifiers.\n(10) Don't ask questions about object size or distance unless there's ample evidence in the image descriptions about object scale or spatial relations. Bounding box details should not be used to infer the sizes or shapes of the objects, becase it is in 2D but the the objects are in complex 3D scenes. Instead of asking \"Which is larger?\", you can ask \"Which object occupies a larger area of the image?\" \n(11) Avoid questions that might be confusing due to similar objects. If bounding boxes are too small or numerous, the AI should avoid forming questions about those objects to avoid confusion. \n(12) Do not mention or refer to the image descriptions in your responses.\n\nHere is an example: \nImage information: \n(1) Image description: \nA photo of two youth soccer teams competing. \nLittle kids play a game of soccer in a field. \nA group of young men kicking around a ball. \nThe small children play soccer on a sunny day. \nChildren run after a soccer ball in the grass. \n\n(2) Objects locations, in the form of bounding box (object: [x1, y1, x2, y2]): \nsports ball: [0.324, 0.769, 0.44, 0.933] \nperson: [0.003, 0.011, 0.202, 0.793] \nperson: [0.125, 0.053, 0.414, 0.868] \nperson: [0.41, 0.001, 0.658, 0.886] \nperson: [0.36, 0.002, 0.476, 0.329] \nperson: [0.187, 0.0, 0.416, 0.258] \nperson: [0.965, 0.003, 1.0, 0.219] \n\nQuestion: Who is more likely to kick the sports ball [0.324, 0.769, 0.44, 0.933] next? \nChoices: (A) The person located to the far left side of the image [0.003, 0.011, 0.202, 0.793] (B) The person located closer to the center of the image [0.125, 0.053, 0.414, 0.868] (C) The person located to the far right side of the image [0.965, 0.003, 1.0, 0.219] (D) The person located closer to the bottom of the image [0.41, 0.001, 0.658, 0.886] \nAnswer: The answer is (B): The person located closer to the center of the image [0.125, 0.053, 0.414, 0.868]. \nExplanations: Based on the distance between the soccer players and the ball in the image, the player closer to the center of the image [0.125, 0.053, 0.414, 0.868] appears to be in the best position to make the next move on the sports ball [0.324, 0.769, 0.44, 0.933]. The player to the far right [0.965, 0.003, 1.0, 0.219] seems too far away, and the players at the bottom [0.41, 0.001, 0.658, 0.886] and far left [0.003, 0.011, 0.202, 0.793] of the image look to be at a disadvantageous position to kick the ball next. \n\nHere is the Image information that I want you to generate high-quality spatial relationship Q&A from: \n(1) Image description: \nA large cat climbing up the side of a window.\nA cat is clinging to the handle on an outside door.\nA cat perched on the handle of a glass door.\nA gray cat climbing a white door with glass panels.\nA cat climbing up the wall between two windows.\n \n\n(2) Objects locations, in the form of bounding box (object: [x1, y1, x2, y2]): \ncat : [0.312, 0.268, 0.604, 0.919]\n \n\nThe question type I require is spatial relationship question. Determine the relative position between objects in image. Following are two examples of the spatial relationship question: \nExample 1: \nQuestion: What does the cat have his paw up against?\nChoices: (A) book (B) mouse (C) toilet (D) desk\nAnswer: The answer is (D): desk.\nQuestion type: spatial relationship \nExample 2: \nQuestion: Which thing is closest to the photographer?\nChoices: (A) long-haired person (B) left elephant (C) woman w/glasses (D) right elephant\nAnswer: The answer is (A): long-haired person.\nQuestion type: spatial relationship \n\nNow you can start to generate one high-quality spatial relationship Q&A about the image according to the image information I gave you.\n\n", "question_type": "spatial_relationship"}, {"image_id": 122161, "prompt": "\nYou are an AI visual assistant that can generate certain type of high-quality Q&A about the images. You will always perform as if you are directly seeing an image. \n\nGoals: \nI will give you some information about this image, along with a question type. Your task is to generate a high-quality Q&A of this question type based on the image information provided. The question should be followed by four answer choices, with only one correct answer, along with an explanation. \n\nThe image information includes 5 descriptions and the locations of specific objects within the image given in the form of bounding boxes. The bounding boxes coordinates are represented as (x1, y1, x2, y2) with floating numbers ranging from 0 to 1. These values correspond to the top left x, top left y, bottom right x, and bottom right y. \n\nRules (If not specified, the following rules apply to all texts you generate): \n(1) Summarize the information provided by image descriptions and objects locations of this image to generate the high-quality Q&A, which should reflect the content of the image. \n(2) Don't generate imaginative or irrelevant content. Ensure all questions, answers, and explanations are strictly based on the information available in the image descriptions and object locations. Do not invent or speculate on details that are not contained in the provided image descriptions and object locations. Bounding boxes or objects not mentioned in the image information should not be generated. \n(3) You must always generate your responses as if you are directly viewing the image, not reading the image descriptions or object locations. Do not mention or refer to the image descriptions in your responses. Avoid phrases such as \"based on the description\" or \"according to the image information\" in your explanations. Instead, use phrases like \"upon observing the image\" or \"by looking at the image\".  \n(4) Do not ask questions that you cannot answer accurately with the given information. \n(5) In the choices, there should be only one correct answer to the question. At the same time, other choices should also be relevant to the question. \n(6) The question you ask should be also answerable without choices. \n(7) Be sure to structure your questions and answers according to the question type. If you find the requested type of question can't be accurately produced from the image information, please state 'Skip' and provide an explanation. \n(8) Don't give any clues or given conditions in question. Invoke visual information as much as possible. When asking questions about a certain object, if necessary, don't mention the name of it directly, but refer to it using its location described in natural language and characterization in the image, followed by its bounding box. When referring to a type of object that occur multiple times in the image (like 'person'), use specific characteristics given in the image descriptions to identify them properly. \n(9) The bounding boxes should not be used as the main identifying feature of the objects in the scene, but rather as a supplement to descriptive identifiers.\n(10) Don't ask questions about object size or distance unless there's ample evidence in the image descriptions about object scale or spatial relations. Bounding box details should not be used to infer the sizes or shapes of the objects, becase it is in 2D but the the objects are in complex 3D scenes. Instead of asking \"Which is larger?\", you can ask \"Which object occupies a larger area of the image?\" \n(11) Avoid questions that might be confusing due to similar objects. If bounding boxes are too small or numerous, the AI should avoid forming questions about those objects to avoid confusion. \n(12) Do not mention or refer to the image descriptions in your responses.\n\nHere is an example: \nImage information: \n(1) Image description: \nA photo of two youth soccer teams competing. \nLittle kids play a game of soccer in a field. \nA group of young men kicking around a ball. \nThe small children play soccer on a sunny day. \nChildren run after a soccer ball in the grass. \n\n(2) Objects locations, in the form of bounding box (object: [x1, y1, x2, y2]): \nsports ball: [0.324, 0.769, 0.44, 0.933] \nperson: [0.003, 0.011, 0.202, 0.793] \nperson: [0.125, 0.053, 0.414, 0.868] \nperson: [0.41, 0.001, 0.658, 0.886] \nperson: [0.36, 0.002, 0.476, 0.329] \nperson: [0.187, 0.0, 0.416, 0.258] \nperson: [0.965, 0.003, 1.0, 0.219] \n\nQuestion: Who is more likely to kick the sports ball [0.324, 0.769, 0.44, 0.933] next? \nChoices: (A) The person located to the far left side of the image [0.003, 0.011, 0.202, 0.793] (B) The person located closer to the center of the image [0.125, 0.053, 0.414, 0.868] (C) The person located to the far right side of the image [0.965, 0.003, 1.0, 0.219] (D) The person located closer to the bottom of the image [0.41, 0.001, 0.658, 0.886] \nAnswer: The answer is (B): The person located closer to the center of the image [0.125, 0.053, 0.414, 0.868]. \nExplanations: Based on the distance between the soccer players and the ball in the image, the player closer to the center of the image [0.125, 0.053, 0.414, 0.868] appears to be in the best position to make the next move on the sports ball [0.324, 0.769, 0.44, 0.933]. The player to the far right [0.965, 0.003, 1.0, 0.219] seems too far away, and the players at the bottom [0.41, 0.001, 0.658, 0.886] and far left [0.003, 0.011, 0.202, 0.793] of the image look to be at a disadvantageous position to kick the ball next. \n\nHere is the Image information that I want you to generate high-quality attribute recognition Q&A from: \n(1) Image description: \nThe people are walking through snow in a wooded area. \nTwo people wearing skis traveling through the snow.\nA man is walking down a path covered in a snow.\nA couple is skiing through the snowy woods. \na couple of people that are in a snowy field\n \n\n(2) Objects locations, in the form of bounding box (object: [x1, y1, x2, y2]): \nperson : [0.383, 0.251, 0.545, 0.74]\nperson : [0.54, 0.42, 0.645, 0.664]\nskis : [0.478, 0.748, 0.489, 0.768]\nskis : [0.374, 0.716, 0.388, 0.741]\n \n\nThe question type I require is attribute recognition question. Recognition of texture, shape, appearance characteristics, emotions, category, celebrities, famous places and objects, optical characters. Following are two examples of the attribute recognition question: \nExample 1: \nQuestion: What kind of clock is this?\nChoices: (A) analog (B) digital (C) sundial (D) cuckoo clock\nAnswer: The answer is (A): analog.\nQuestion type: attribute recognition \nExample 2: \nQuestion: What is the most diverse seashore bird?\nChoices: (A) sandpiper (B) crow (C) pelican (D) seagull\nAnswer: The answer is (A): sandpiper.\nQuestion type: attribute recognition \n\nNow you can start to generate one high-quality attribute recognition Q&A about the image according to the image information I gave you.\n\n", "question_type": "attribute_recognition"}]